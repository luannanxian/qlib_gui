
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
</head>
<body>
<div itemprop="articleBody">
<section id="quick-start">
<h1>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>QlibRL provides an example of an implementation of a single asset order execution task and the following is an example of the config file to train with QlibRL.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">simulator</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Each step contains 30mins</span>
<span class="w">    </span><span class="nt">time_per_step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30</span>
<span class="w">    </span><span class="c1"># Upper bound of volume, should be null or a float between 0 and 1, if it is a float, represent upper bound is calculated by the percentage of the market volume</span>
<span class="w">    </span><span class="nt">vol_limit</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">env</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Concurrent environment workers.</span>
<span class="w">    </span><span class="nt">concurrency</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="c1"># dummy or subproc or shmem. Corresponding to `parallelism in tianshou &lt;https://tianshou.readthedocs.io/en/master/api/tianshou.env.html#vectorenv&gt;`_.</span>
<span class="w">    </span><span class="nt">parallel_mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dummy</span>
<span class="nt">action_interpreter</span><span class="p">:</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CategoricalActionInterpreter</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># Candidate actions, it can be a list with length L: [a_1, a_2,..., a_L] or an integer n, in which case the list of length n+1 is auto-generated, i.e., [0, 1/n, 2/n,..., n/n].</span>
<span class="w">        </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">14</span>
<span class="w">        </span><span class="c1"># Total number of steps (an upper-bound estimation)</span>
<span class="w">        </span><span class="nt">max_step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.interpreter</span>
<span class="nt">state_interpreter</span><span class="p">:</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">FullHistoryStateInterpreter</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># Number of dimensions in data.</span>
<span class="w">        </span><span class="nt">data_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">        </span><span class="c1"># Equal to the total number of records. For example, in SAOE per minute, data_ticks is the length of the day in minutes.</span>
<span class="w">        </span><span class="nt">data_ticks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">240</span>
<span class="w">        </span><span class="c1"># The total number of steps (an upper-bound estimation). For example, 390min / 30min-per-step = 13 steps.</span>
<span class="w">        </span><span class="nt">max_step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">        </span><span class="c1"># Provider of the processed data.</span>
<span class="w">        </span><span class="nt">processed_data_provider</span><span class="p">:</span>
<span class="w">            </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PickleProcessedDataProvider</span>
<span class="w">            </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.data.pickle_styled</span>
<span class="w">            </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">                </span><span class="nt">data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/pickle_dataframe/feature</span>
<span class="w">    </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.interpreter</span>
<span class="nt">reward</span><span class="p">:</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PAPenaltyReward</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># The penalty for a large volume in a short time.</span>
<span class="w">        </span><span class="nt">penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100.0</span>
<span class="w">    </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.reward</span>
<span class="nt">data</span><span class="p">:</span>
<span class="w">    </span><span class="nt">source</span><span class="p">:</span>
<span class="w">        </span><span class="nt">order_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/training_order_split</span>
<span class="w">        </span><span class="nt">data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/pickle_dataframe/backtest</span>
<span class="w">        </span><span class="c1"># number of time indexes</span>
<span class="w">        </span><span class="nt">total_time</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">240</span>
<span class="w">        </span><span class="c1"># start time index</span>
<span class="w">        </span><span class="nt">default_start_time</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">        </span><span class="c1"># end time index</span>
<span class="w">        </span><span class="nt">default_end_time</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">240</span>
<span class="w">        </span><span class="nt">proc_data_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">queue_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
<span class="nt">network</span><span class="p">:</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Recurrent</span>
<span class="w">    </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.network</span>
<span class="nt">policy</span><span class="p">:</span>
<span class="w">    </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PPO</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0001</span>
<span class="w">    </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.policy</span>
<span class="nt">runtime</span><span class="p">:</span>
<span class="w">    </span><span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">42</span>
<span class="w">    </span><span class="nt">use_cuda</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">trainer</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_epoch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="c1"># Number of episodes collected in each training iteration</span>
<span class="w">    </span><span class="nt">repeat_per_collect</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">    </span><span class="nt">earlystop_patience</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="c1"># Episodes per collect at training.</span>
<span class="w">    </span><span class="nt">episode_per_collect</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>
<span class="w">    </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="w">    </span><span class="c1"># Perform validation every n iterations</span>
<span class="w">    </span><span class="nt">val_every_n_epoch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">checkpoint_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./checkpoints</span>
<span class="w">    </span><span class="nt">checkpoint_every_n_iters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</pre></div>
</div>
<p>And the config file for backtesting:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">order_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/backtest_orders.csv</span>
<span class="nt">start_time</span><span class="p">:</span><span class="w"> </span><span class="s">"9:45"</span>
<span class="nt">end_time</span><span class="p">:</span><span class="w"> </span><span class="s">"14:44"</span>
<span class="nt">qlib</span><span class="p">:</span>
<span class="w">    </span><span class="nt">provider_uri_1min</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/bin</span>
<span class="w">    </span><span class="nt">feature_root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/pickle</span>
<span class="w">    </span><span class="c1"># feature generated by today's information</span>
<span class="w">    </span><span class="nt">feature_columns_today</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span>
<span class="w">        </span><span class="s">"$open"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$high"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$low"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$close"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$vwap"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$volume"</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="c1"># feature generated by yesterday's information</span>
<span class="w">    </span><span class="nt">feature_columns_yesterday</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span>
<span class="w">        </span><span class="s">"$open_v1"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$high_v1"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$low_v1"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$close_v1"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$vwap_v1"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$volume_v1"</span><span class="p p-Indicator">,</span>
<span class="w">    </span><span class="p p-Indicator">]</span>
<span class="nt">exchange</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># the expression for buying and selling stock limitation</span>
<span class="w">    </span><span class="nt">limit_threshold</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">'$close</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">0'</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">'$close</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">0'</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="c1"># deal price for buying and selling</span>
<span class="w">    </span><span class="nt">deal_price</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"If($close</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">0,</span><span class="nv"> </span><span class="s">$vwap,</span><span class="nv"> </span><span class="s">$close)"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"If($close</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">0,</span><span class="nv"> </span><span class="s">$vwap,</span><span class="nv"> </span><span class="s">$close)"</span><span class="p p-Indicator">]</span>
<span class="nt">volume_threshold</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># volume limits are both buying and selling, "cum" means that this is a cumulative value over time</span>
<span class="w">    </span><span class="nt">all</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"cum"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"0.2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">DayCumsum($volume,</span><span class="nv"> </span><span class="s">'9:45',</span><span class="nv"> </span><span class="s">'14:44')"</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="c1"># the volume limits of buying</span>
<span class="w">    </span><span class="nt">buy</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"current"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$close"</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="c1"># the volume limits of selling, "current" means that this is a real-time value and will not accumulate over time</span>
<span class="w">    </span><span class="nt">sell</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"current"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"$close"</span><span class="p p-Indicator">]</span>
<span class="nt">strategies</span><span class="p">:</span>
<span class="w">    </span><span class="nt">30min</span><span class="p">:</span>
<span class="w">        </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TWAPStrategy</span>
<span class="w">        </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.contrib.strategy.rule_strategy</span>
<span class="w">        </span><span class="nt">kwargs</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
<span class="w">    </span><span class="nt">1day</span><span class="p">:</span>
<span class="w">        </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SAOEIntStrategy</span>
<span class="w">        </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.strategy</span>
<span class="w">        </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">state_interpreter</span><span class="p">:</span>
<span class="w">            </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">FullHistoryStateInterpreter</span>
<span class="w">            </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.interpreter</span>
<span class="w">            </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">            </span><span class="nt">max_step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">            </span><span class="nt">data_ticks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">240</span>
<span class="w">            </span><span class="nt">data_dim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">            </span><span class="nt">processed_data_provider</span><span class="p">:</span>
<span class="w">                </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PickleProcessedDataProvider</span>
<span class="w">                </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.data.pickle_styled</span>
<span class="w">                </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">                </span><span class="nt">data_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/pickle_dataframe/feature</span>
<span class="w">        </span><span class="nt">action_interpreter</span><span class="p">:</span>
<span class="w">            </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CategoricalActionInterpreter</span>
<span class="w">            </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.interpreter</span>
<span class="w">            </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">            </span><span class="nt">values</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">14</span>
<span class="w">            </span><span class="nt">max_step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">        </span><span class="nt">network</span><span class="p">:</span>
<span class="w">            </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Recurrent</span>
<span class="w">            </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.network</span>
<span class="w">            </span><span class="nt">kwargs</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
<span class="w">        </span><span class="nt">policy</span><span class="p">:</span>
<span class="w">            </span><span class="nt">class</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PPO</span>
<span class="w">            </span><span class="nt">module_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">qlib.rl.order_execution.policy</span>
<span class="w">            </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">                </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-4</span>
<span class="w">                </span><span class="c1"># Local path to the latest model. The model is generated during training, so please run training first if you want to run backtest with a trained policy. You could also remove this parameter file to run backtest with a randomly initialized policy.</span>
<span class="w">                </span><span class="nt">weight_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./checkpoints/latest.pth</span>
<span class="c1"># Concurrent environment workers.</span>
<span class="nt">concurrency</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
</pre></div>
</div>
<p>With the above config files, you can start training the agent by the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python<span class="w"> </span>-m<span class="w"> </span>qlib.rl.contrib.train_onpolicy.py<span class="w"> </span>--config_path<span class="w"> </span>train_config.yml
</pre></div>
</div>
<p>After the training, you can backtest with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python<span class="w"> </span>-m<span class="w"> </span>qlib.rl.contrib.backtest.py<span class="w"> </span>--config_path<span class="w"> </span>backtest_config.yml
</pre></div>
</div>
<p>In that case, <code class="xref py py-class docutils literal notranslate"><span class="pre">SingleAssetOrderExecution</span></code> and <a class="reference internal" href="../../reference/api.html#qlib.rl.order_execution.SingleAssetOrderExecutionSimple" title="qlib.rl.order_execution.simulator_simple.SingleAssetOrderExecutionSimple"><code class="xref py py-class docutils literal notranslate"><span class="pre">SingleAssetOrderExecutionSimple</span></code></a> as examples for simulator, <a class="reference internal" href="../../reference/api.html#qlib.rl.order_execution.FullHistoryStateInterpreter" title="qlib.rl.order_execution.interpreter.FullHistoryStateInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">qlib.rl.order_execution.interpreter.FullHistoryStateInterpreter</span></code></a> and <a class="reference internal" href="../../reference/api.html#qlib.rl.order_execution.CategoricalActionInterpreter" title="qlib.rl.order_execution.interpreter.CategoricalActionInterpreter"><code class="xref py py-class docutils literal notranslate"><span class="pre">qlib.rl.order_execution.interpreter.CategoricalActionInterpreter</span></code></a> as examples for interpreter, <a class="reference internal" href="../../reference/api.html#qlib.rl.order_execution.PPO" title="qlib.rl.order_execution.policy.PPO"><code class="xref py py-class docutils literal notranslate"><span class="pre">qlib.rl.order_execution.policy.PPO</span></code></a> as an example for policy, and <a class="reference internal" href="../../reference/api.html#qlib.rl.order_execution.PAPenaltyReward" title="qlib.rl.order_execution.reward.PAPenaltyReward"><code class="xref py py-class docutils literal notranslate"><span class="pre">qlib.rl.order_execution.reward.PAPenaltyReward</span></code></a> as an example for reward.
For the single asset order execution task, if developers have already defined their simulator/interpreters/reward function/policy, they could launch the training and backtest pipeline by simply modifying the corresponding settings in the config files.
The details about the example can be found <a class="reference external" href="https://github.com/microsoft/qlib/blob/main/examples/rl/README.md">here</a>.</p>
<p>In the future, we will provide more examples for different scenarios such as RL-based portfolio construction.</p>
</section>
</div>
</body>
</html>
